# Dockerfile

# Use an official Python runtime as a parent image
# python:3.9-slim-buster is a good choice for stability and smaller image size
# You can choose python:3.10-slim-buster or python:3.11-slim-buster if you prefer,
# but ensure consistency with your local development environment.
FROM python:3.9-slim-buster 

# Set the working directory in the container to /app
# All subsequent commands will be executed relative to this directory
WORKDIR /app

# Install any necessary system-level dependencies.
# For this project, apt-get update is good practice. No specific external libraries are usually needed.
# If you later add libraries that require system packages (e.g., geospatial libraries like GDAL/GEOS),
# you might need to uncomment and add them here (e.g., libgdal-dev).
# RUN apt-get update && apt-get install -y --no-install-recommends \
#     # add system dependencies here, e.g., git \
#     && rm -rf /var/lib/apt/lists/*

# Copy the requirements.txt file into the working directory
# This step is done separately before copying all other code to leverage Docker's layer caching.
# If only requirements.txt changes, Docker can reuse the previous layer for pip install.
COPY requirements.txt .

# Install Python dependencies from requirements.txt
# --no-cache-dir: Reduces the image size by not storing pip's build cache
# -r requirements.txt: Installs all packages listed in the requirements file
RUN pip install --no-cache-dir -r requirements.txt

# Copy the entire project directory into the /app directory of the container.
# This copies all your Python files (main.py, dashboard_app.py, etc.)
# Files/folders specified in .dockerignore (if present) or .gitignore are excluded.
COPY . .

# Create necessary data and output directories within the container.
# Your Python scripts (like dashboard_app.py) will attempt to write
# synthetic data CSVs and map HTML files into these directories.
# `mkdir -p` ensures parent directories are created if they don't exist.
RUN mkdir -p data output

# Define the command to execute when the container starts.
# We use 'sh -c' to allow chaining multiple commands.
# 1. 'python main.py': Executes your main backend logic. This includes:
#    - Generating synthetic raw data if it doesn't exist.
#    - Performing initial preprocessing.
#    - Training initial models (this can take time and consume memory).
#    - It will *block* until this script finishes.
#    - Any Matplotlib plots generated by main.py will not pop up visually in a container,
#      but the script will still pause until they are "closed" internally by the process.
# 2. '&&': This is a shell operator that means "AND." The next command will only
#    execute if 'python main.py' completes successfully (exits with a zero status code).
# 3. 'streamlit run dashboard_app.py': Starts your Streamlit web application.
#    --server.port 8501: Explicitly tells Streamlit to listen on port 8501.
#    --server.enableCORS false: Crucial for allowing cross-origin requests, needed for public web access.
#    --server.enableXsrfProtection false: Disables XSRF protection (often needed for public demos).
#                                        Be aware of security implications in true production.
CMD ["sh", "-c", "python main.py && streamlit run dashboard_app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false"]

# Expose the port that Streamlit runs on.
# This tells Docker that the container provides a service on this port.
# When deploying to a cloud platform, this port will be mapped to a public URL.
EXPOSE 8501